{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['admission_age', 'temperature', 'heartrate', 'resprate', 'o2sat', 'sbp',\n",
       "       'dbp', 'acuity', 'stay_length_minutes', 'pain_cleaned_advanced',\n",
       "       'gender_F', 'gender_M', 'arrival_transport_AMBULANCE',\n",
       "       'arrival_transport_HELICOPTER', 'arrival_transport_OTHER',\n",
       "       'arrival_transport_UNKNOWN', 'arrival_transport_WALK IN',\n",
       "       'race_condensed_AMERICAN INDIAN/ALASKA NATIVE', 'race_condensed_ASIAN',\n",
       "       'race_condensed_BLACK', 'race_condensed_HISPANIC/LATINO',\n",
       "       'race_condensed_Missing',\n",
       "       'race_condensed_NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER',\n",
       "       'race_condensed_OTHER', 'race_condensed_White'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../DataCleaning/train_imputed.csv')\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d5/3vmjgsdd5tx_pz5vmfxtrtrc0000gn/T/ipykernel_5109/2960933145.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cc_columns]=df_pca\n"
     ]
    }
   ],
   "source": [
    "df_pca=np.load('../chief_complaint_data/train_pca.npy')\n",
    "cc_columns= [f'cc_{i}' for i in range(100)]\n",
    "df[cc_columns]=df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['admission_age', 'temperature', 'heartrate', 'resprate', 'o2sat', 'sbp',\n",
    "       'dbp', 'acuity', 'pain_cleaned_advanced',\n",
    "       'gender_F', 'gender_M', 'arrival_transport_AMBULANCE',\n",
    "       'arrival_transport_HELICOPTER', 'arrival_transport_OTHER',\n",
    "       'arrival_transport_UNKNOWN', 'arrival_transport_WALK IN',\n",
    "       'race_condensed_AMERICAN INDIAN/ALASKA NATIVE', 'race_condensed_ASIAN',\n",
    "       'race_condensed_BLACK', 'race_condensed_HISPANIC/LATINO',\n",
    "       'race_condensed_Missing',\n",
    "       'race_condensed_NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER',\n",
    "       'race_condensed_OTHER', 'race_condensed_White'\n",
    "       ]+cc_columns\n",
    "\n",
    "triage_physical_features=['temperature', 'heartrate', 'resprate', 'o2sat', 'sbp',\n",
    "       'dbp']\n",
    "triage_other_features=['pain_cleaned_advanced','acuity', 'arrival_transport_AMBULANCE',\n",
    "       'arrival_transport_HELICOPTER', 'arrival_transport_OTHER',\n",
    "       'arrival_transport_UNKNOWN', 'arrival_transport_WALK IN']\n",
    "demographic_features=['admission_age',\n",
    "       'gender_F', 'gender_M',\n",
    "       'race_condensed_AMERICAN INDIAN/ALASKA NATIVE', 'race_condensed_ASIAN',\n",
    "       'race_condensed_BLACK', 'race_condensed_HISPANIC/LATINO',\n",
    "       'race_condensed_Missing',\n",
    "       'race_condensed_NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER',\n",
    "       'race_condensed_OTHER', 'race_condensed_White']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits = 5,\n",
    "              shuffle = True,\n",
    "              random_state = 111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00183184, 1.00403026, 1.00182546, 0.98867385, 1.00355666],\n",
       "       [0.99812281, 1.00133898, 0.99832365, 0.98559571, 1.00046329],\n",
       "       [0.97253621, 0.97361566, 0.97287354, 0.95961193, 0.97224261],\n",
       "       [0.96859696, 0.96977646, 0.96917978, 0.95586109, 0.96837689],\n",
       "       [0.93349465, 0.93194395, 0.93080743, 0.91640876, 0.93057846]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trying out linear regression with various predictor variable sets.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "mean=np.mean(df['stay_length_minutes'])\n",
    "mlr_phys = LinearRegression()\n",
    "mlr_phys_other=LinearRegression()\n",
    "mlr_phys_other_dem=LinearRegression()\n",
    "mlr_all=LinearRegression()\n",
    "\n",
    "#rmses will hold the cross validation root mean squared errors of each model. \n",
    "rmses = np.zeros((5, 5))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(df)):\n",
    "    ## get the kfold training data\n",
    "    X_train_train = df[features].iloc[train_index,:]\n",
    "    y_train_train = df['stay_length_minutes'].iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = df[features].iloc[test_index,:]\n",
    "    y_holdout = df['stay_length_minutes'].iloc[test_index]\n",
    "\n",
    "    ## Fit models\n",
    "    mlr_phys.fit(X_train_train[triage_physical_features], y_train_train)\n",
    "    mlr_phys_other.fit(X_train_train[triage_physical_features+triage_other_features], y_train_train)\n",
    "    mlr_phys_other_dem.fit(X_train_train[triage_physical_features+triage_other_features+demographic_features], y_train_train)\n",
    "    mlr_all.fit(X_train_train[triage_physical_features+triage_other_features+demographic_features+cc_columns], y_train_train)\n",
    "    \n",
    "    ## Use models to generate predictions on the holdout set\n",
    "    mean_preds = mean*np.ones(len(y_holdout))\n",
    "    mlr_phys_preds = mlr_phys.predict(X_holdout[triage_physical_features])\n",
    "    mlr_phys_other_preds = mlr_phys_other.predict(X_holdout[triage_physical_features+triage_other_features])\n",
    "    mlr_phys_other_dem_preds = mlr_phys_other_dem.predict(X_holdout[triage_physical_features+triage_other_features+demographic_features])\n",
    "    mlr_all_preds = mlr_all.predict(X_holdout[triage_physical_features+triage_other_features+demographic_features+cc_columns])\n",
    "\n",
    "\n",
    "    ## Record the rmses\n",
    "    rmses[0,i] = root_mean_squared_error(y_holdout, mean_preds)\n",
    "    rmses[1,i] = root_mean_squared_error(y_holdout, mlr_phys_preds)\n",
    "    rmses[2,i] = root_mean_squared_error(y_holdout, mlr_phys_other_preds)\n",
    "    rmses[3,i] = root_mean_squared_error(y_holdout, mlr_phys_other_dem_preds)\n",
    "    rmses[4,i] = root_mean_squared_error(y_holdout, mlr_all_preds)\n",
    "\n",
    "rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ColumnTransformer\n",
    "polyprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('poly', PolynomialFeatures(degree=2), triage_physical_features+triage_other_features),\n",
    "        ('passthrough', 'passthrough', demographic_features+cc_columns)\n",
    "    ],\n",
    "    remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00183184, 1.00403026, 1.00182546, 0.98867385, 1.00355666],\n",
       "       [0.99812281, 1.00133898, 0.99832365, 0.98559571, 1.00046329],\n",
       "       [0.97253621, 0.97361566, 0.97287354, 0.95961193, 0.97224261],\n",
       "       [0.96859696, 0.96977646, 0.96917978, 0.95586109, 0.96837689],\n",
       "       [0.93349465, 0.93194395, 0.93080743, 0.91640876, 0.93057846],\n",
       "       [0.9174154 , 0.91518426, 0.91069693, 0.90204174, 0.91144705]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding in polynomial terms up to degree 3 for the non-chief-complaint terms.\n",
    "\n",
    "mean=np.mean(df['stay_length_minutes'])\n",
    "mlr_phys = LinearRegression()\n",
    "mlr_phys_other=LinearRegression()\n",
    "mlr_phys_other_dem=LinearRegression()\n",
    "mlr_all=LinearRegression()\n",
    "mlr_poly=LinearRegression()\n",
    "\n",
    "#rmses will hold the cross validation root mean squared errors of each model. \n",
    "rmses = np.zeros((6, 5))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(df)):\n",
    "    ## get the kfold training data\n",
    "    X_train_train = df[features].iloc[train_index,:]\n",
    "    y_train_train = df['stay_length_minutes'].iloc[train_index]\n",
    "    X_train_transformed=polyprocessor.fit_transform(X_train_train)\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = df[features].iloc[test_index,:]\n",
    "    y_holdout = df['stay_length_minutes'].iloc[test_index]\n",
    "    X_holdout_transformed=polyprocessor.fit_transform(X_holdout)\n",
    "\n",
    "    ## Fit models\n",
    "    mlr_phys.fit(X_train_train[triage_physical_features], y_train_train)\n",
    "    mlr_phys_other.fit(X_train_train[triage_physical_features+triage_other_features], y_train_train)\n",
    "    mlr_phys_other_dem.fit(X_train_train[triage_physical_features+triage_other_features+demographic_features], y_train_train)\n",
    "    mlr_all.fit(X_train_train[triage_physical_features+triage_other_features+demographic_features+cc_columns], y_train_train)\n",
    "    mlr_poly.fit(X_train_transformed, y_train_train)\n",
    "\n",
    "    ## Use models to generate predictions on the holdout set\n",
    "    mean_preds = mean*np.ones(len(y_holdout))\n",
    "    mlr_phys_preds = mlr_phys.predict(X_holdout[triage_physical_features])\n",
    "    mlr_phys_other_preds = mlr_phys_other.predict(X_holdout[triage_physical_features+triage_other_features])\n",
    "    mlr_phys_other_dem_preds = mlr_phys_other_dem.predict(X_holdout[triage_physical_features+triage_other_features+demographic_features])\n",
    "    mlr_all_preds = mlr_all.predict(X_holdout[triage_physical_features+triage_other_features+demographic_features+cc_columns])\n",
    "    mlr_poly_preds=mlr_poly.predict(X_holdout_transformed)\n",
    "\n",
    "    ## Record the rmses\n",
    "    rmses[0,i] = root_mean_squared_error(y_holdout, mean_preds)\n",
    "    rmses[1,i] = root_mean_squared_error(y_holdout, mlr_phys_preds)\n",
    "    rmses[2,i] = root_mean_squared_error(y_holdout, mlr_phys_other_preds)\n",
    "    rmses[3,i] = root_mean_squared_error(y_holdout, mlr_phys_other_dem_preds)\n",
    "    rmses[4,i] = root_mean_squared_error(y_holdout, mlr_all_preds)\n",
    "    rmses[5,i] = root_mean_squared_error(y_holdout, mlr_poly_preds)\n",
    "\n",
    "rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99998361, 0.99676889, 0.97017599, 0.96635824, 0.92864665,\n",
       "       0.91135708])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmses, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00183184, 1.00403026, 1.00182546, 0.98867385, 1.00355666],\n",
       "       [0.94999768, 0.94783958, 0.94585772, 0.93617221, 0.94363494],\n",
       "       [0.94999768, 0.94783958, 0.94585772, 0.93617221, 0.94363494],\n",
       "       [0.88142499, 0.88222369, 0.88233063, 0.8753496 , 0.88258166],\n",
       "       [0.86943762, 0.87109872, 0.86894691, 0.86147213, 0.86848175],\n",
       "       [0.77082506, 0.76955162, 0.76735617, 0.76565038, 0.76195427],\n",
       "       [0.70438008, 0.71555458, 0.7106086 , 0.7004532 , 0.70405932]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying decision trees with a range of max depths.\n",
    "\n",
    "tree2 = DecisionTreeRegressor(max_depth=2, random_state=108)\n",
    "tree2_nocc = DecisionTreeRegressor(max_depth=2, random_state=108)\n",
    "tree5 = DecisionTreeRegressor(max_depth=5, random_state=108)\n",
    "tree5_nocc = DecisionTreeRegressor(max_depth=5, random_state=108)\n",
    "tree10 = DecisionTreeRegressor(max_depth=10, random_state=108)\n",
    "tree10_nocc = DecisionTreeRegressor(max_depth=10, random_state=108)\n",
    "\n",
    "rmses = np.zeros((7, 5))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(df)):\n",
    "    ## get the kfold training data\n",
    "    X_train_train = df[features].iloc[train_index,:]\n",
    "    y_train_train = df['stay_length_minutes'].iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = df[features].iloc[test_index,:]\n",
    "    y_holdout = df['stay_length_minutes'].iloc[test_index]\n",
    "\n",
    "    ## Fit models\n",
    "    tree2.fit(X_train_train, y_train_train)\n",
    "    tree2_nocc.fit(X_train_train[triage_physical_features+triage_other_features+demographic_features],y_train_train)\n",
    "    tree5.fit(X_train_train, y_train_train)\n",
    "    tree5_nocc.fit(X_train_train[triage_physical_features+triage_other_features+demographic_features], y_train_train)\n",
    "    tree10.fit(X_train_train, y_train_train)\n",
    "    tree10_nocc.fit(X_train_train[triage_physical_features+triage_other_features+demographic_features], y_train_train)\n",
    "\n",
    "    ## Use models to generate predictions on the holdout set\n",
    "    mean_preds = mean*np.ones(len(y_holdout))\n",
    "    tree2_preds = tree2.predict(X_holdout)\n",
    "    tree2_nocc_preds=tree2_nocc.predict(X_holdout[triage_physical_features+triage_other_features+demographic_features])\n",
    "    tree5_preds = tree5.predict(X_holdout)\n",
    "    tree5_nocc_preds=tree5_nocc.predict(X_holdout[triage_physical_features+triage_other_features+demographic_features])\n",
    "    tree10_preds = tree10.predict(X_holdout)\n",
    "    tree10_nocc_preds=tree10_nocc.predict(X_holdout[triage_physical_features+triage_other_features+demographic_features])\n",
    "    \n",
    "\n",
    "    ## Record the rmses\n",
    "    rmses[0,i] = root_mean_squared_error(y_holdout, mean_preds)\n",
    "    rmses[1,i] = root_mean_squared_error(y_holdout, tree2_preds)\n",
    "    rmses[2,i]=root_mean_squared_error(y_holdout, tree2_nocc_preds)\n",
    "    rmses[3,i] = root_mean_squared_error(y_holdout, tree5_preds)\n",
    "    rmses[4,i] = root_mean_squared_error(y_holdout, tree5_nocc_preds)\n",
    "    rmses[5,i] = root_mean_squared_error(y_holdout, tree10_preds)\n",
    "    rmses[6,i] = root_mean_squared_error(y_holdout, tree10_nocc_preds)\n",
    "\n",
    "\n",
    "rmses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88142499, 0.88222369, 0.88233063, 0.8753496 , 0.88258166],\n",
       "       [0.87725392, 0.87779858, 0.87782022, 0.87929478, 0.87714591],\n",
       "       [0.86943762, 0.87109872, 0.86894691, 0.86147213, 0.86848175],\n",
       "       [0.86420684, 0.86449354, 0.86527167, 0.86659834, 0.86447826],\n",
       "       [0.77082506, 0.76955162, 0.76735617, 0.76565038, 0.76195427],\n",
       "       [0.74847335, 0.74765683, 0.74829975, 0.74869558, 0.74515222],\n",
       "       [0.70438008, 0.71555458, 0.7106086 , 0.7004532 , 0.70405932],\n",
       "       [0.68788935, 0.69587668, 0.69456647, 0.69504697, 0.68455973],\n",
       "       [0.70751588, 0.69332476, 0.68553154, 0.70162094, 0.70690797],\n",
       "       [0.40732721, 0.40012604, 0.40673543, 0.40261036, 0.39656905],\n",
       "       [0.63183937, 0.63065551, 0.64236393, 0.62494255, 0.63003946],\n",
       "       [0.34198266, 0.35625367, 0.35597227, 0.36987347, 0.35979516]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#More decision trees for different depths. This time I also compare performance on \n",
    "# the test set to the training set in the cross validation.\n",
    "\n",
    "tree5 = DecisionTreeRegressor(max_depth=5, random_state=108)\n",
    "tree5_nocc = DecisionTreeRegressor(max_depth=5, random_state=108)\n",
    "tree10 = DecisionTreeRegressor(max_depth=10, random_state=108)\n",
    "tree10_nocc = DecisionTreeRegressor(max_depth=10, random_state=108)\n",
    "tree20 = DecisionTreeRegressor(max_depth=20, random_state=108)\n",
    "tree20_nocc = DecisionTreeRegressor(max_depth=20, random_state=108)\n",
    "\n",
    "rmses = np.zeros((12, 5))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(df)):\n",
    "    ## get the kfold training data\n",
    "    X_train_train = df[features].iloc[train_index,:]\n",
    "    y_train_train = df['stay_length_minutes'].iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = df[features].iloc[test_index,:]\n",
    "    y_holdout = df['stay_length_minutes'].iloc[test_index]\n",
    "\n",
    "    ## Fit models\n",
    "    tree5.fit(X_train_train, y_train_train)\n",
    "    tree5_nocc.fit(X_train_train[triage_physical_features+triage_other_features+demographic_features], y_train_train)\n",
    "    tree10.fit(X_train_train, y_train_train)\n",
    "    tree10_nocc.fit(X_train_train[triage_physical_features+triage_other_features+demographic_features], y_train_train)\n",
    "    tree20.fit(X_train_train, y_train_train)\n",
    "    tree20_nocc.fit(X_train_train[triage_physical_features+triage_other_features+demographic_features], y_train_train)\n",
    "\n",
    "\n",
    "    ## Use models to generate predictions on the holdout set\n",
    "    tree5_preds = tree5.predict(X_holdout)\n",
    "    tree5_preds_train = tree5.predict(X_train_train)\n",
    "    tree5_nocc_preds=tree5_nocc.predict(X_holdout[triage_physical_features+triage_other_features+demographic_features])\n",
    "    tree5_nocc_preds_train=tree5_nocc.predict(X_train_train[triage_physical_features+triage_other_features+demographic_features])\n",
    "    tree10_preds = tree10.predict(X_holdout)\n",
    "    tree10_preds_train = tree10.predict(X_train_train)\n",
    "    tree10_nocc_preds=tree10_nocc.predict(X_holdout[triage_physical_features+triage_other_features+demographic_features])\n",
    "    tree10_nocc_preds_train=tree10_nocc.predict(X_train_train[triage_physical_features+triage_other_features+demographic_features])\n",
    "    tree20_preds = tree20.predict(X_holdout)\n",
    "    tree20_preds_train = tree20.predict(X_train_train)\n",
    "    tree20_nocc_preds=tree20_nocc.predict(X_holdout[triage_physical_features+triage_other_features+demographic_features])\n",
    "    tree20_nocc_preds_train=tree20_nocc.predict(X_train_train[triage_physical_features+triage_other_features+demographic_features])\n",
    "    \n",
    "\n",
    "    ## Record the rmses\n",
    "    rmses[0,i] = root_mean_squared_error(y_holdout, tree5_preds)\n",
    "    rmses[1,i] = root_mean_squared_error(y_train_train, tree5_preds_train)\n",
    "    rmses[2,i] = root_mean_squared_error(y_holdout, tree5_nocc_preds)\n",
    "    rmses[3,i] = root_mean_squared_error(y_train_train, tree5_nocc_preds_train)\n",
    "    rmses[4,i] = root_mean_squared_error(y_holdout, tree10_preds)\n",
    "    rmses[5,i] = root_mean_squared_error(y_train_train, tree10_preds_train)\n",
    "    rmses[6,i] = root_mean_squared_error(y_holdout, tree10_nocc_preds)\n",
    "    rmses[7,i] = root_mean_squared_error(y_train_train, tree10_nocc_preds_train)\n",
    "    rmses[8,i] = root_mean_squared_error(y_holdout, tree20_preds)\n",
    "    rmses[9,i] = root_mean_squared_error(y_train_train, tree20_preds_train)\n",
    "    rmses[10,i] = root_mean_squared_error(y_holdout, tree20_nocc_preds)\n",
    "    rmses[11,i] = root_mean_squared_error(y_train_train, tree20_nocc_preds_train)\n",
    "\n",
    "\n",
    "rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 completed\n",
      "Round 1 completed\n",
      "Round 2 completed\n",
      "Round 3 completed\n",
      "Round 4 completed\n",
      "Round 5 completed\n",
      "Round 6 completed\n",
      "Round 7 completed\n",
      "Round 8 completed\n",
      "Round 9 completed\n",
      "Round 10 completed\n",
      "Round 11 completed\n",
      "Round 12 completed\n",
      "Round 13 completed\n",
      "Round 14 completed\n",
      "Round 0 completed\n",
      "Round 1 completed\n",
      "Round 2 completed\n",
      "Round 3 completed\n",
      "Round 4 completed\n",
      "Round 5 completed\n",
      "Round 6 completed\n",
      "Round 7 completed\n",
      "Round 8 completed\n",
      "Round 9 completed\n",
      "Round 10 completed\n",
      "Round 11 completed\n",
      "Round 12 completed\n",
      "Round 13 completed\n",
      "Round 14 completed\n",
      "Round 0 completed\n",
      "Round 1 completed\n",
      "Round 2 completed\n",
      "Round 3 completed\n",
      "Round 4 completed\n",
      "Round 5 completed\n",
      "Round 6 completed\n",
      "Round 7 completed\n",
      "Round 8 completed\n",
      "Round 9 completed\n",
      "Round 10 completed\n",
      "Round 11 completed\n",
      "Round 12 completed\n",
      "Round 13 completed\n",
      "Round 14 completed\n",
      "Round 0 completed\n",
      "Round 1 completed\n",
      "Round 2 completed\n",
      "Round 3 completed\n",
      "Round 4 completed\n",
      "Round 5 completed\n",
      "Round 6 completed\n",
      "Round 7 completed\n",
      "Round 8 completed\n",
      "Round 9 completed\n",
      "Round 10 completed\n",
      "Round 11 completed\n",
      "Round 12 completed\n",
      "Round 13 completed\n",
      "Round 14 completed\n",
      "Round 0 completed\n",
      "Round 1 completed\n",
      "Round 2 completed\n",
      "Round 3 completed\n",
      "Round 4 completed\n",
      "Round 5 completed\n",
      "Round 6 completed\n",
      "Round 7 completed\n",
      "Round 8 completed\n",
      "Round 9 completed\n",
      "Round 10 completed\n",
      "Round 11 completed\n",
      "Round 12 completed\n",
      "Round 13 completed\n",
      "Round 14 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.88142499, 0.88222369, 0.88233063, 0.8753496 , 0.88258166],\n",
       "       [0.87725392, 0.87779858, 0.87782022, 0.87929478, 0.87714591],\n",
       "       [0.86943762, 0.87109872, 0.86894691, 0.86147213, 0.86848175],\n",
       "       [0.86420684, 0.86449354, 0.86527167, 0.86659834, 0.86447826],\n",
       "       [0.86340532, 0.8651636 , 0.86648112, 0.85680474, 0.86400179],\n",
       "       [0.85822781, 0.85860002, 0.85850904, 0.8606057 , 0.85781784],\n",
       "       [0.83955299, 0.83616671, 0.8367221 , 0.83683891, 0.83670047],\n",
       "       [0.83301221, 0.83469761, 0.83423929, 0.83442696, 0.83333844],\n",
       "       [0.84363622, 0.84458914, 0.84359773, 0.83725371, 0.84214111],\n",
       "       [0.83571415, 0.8362921 , 0.83690867, 0.83815312, 0.83509821],\n",
       "       [0.80651324, 0.80660989, 0.80449923, 0.80163389, 0.80325781],\n",
       "       [0.79941313, 0.80165528, 0.80059583, 0.79908011, 0.79749225],\n",
       "       [0.82372958, 0.81839448, 0.82336112, 0.81995529, 0.81922862],\n",
       "       [0.8115156 , 0.81267704, 0.81189198, 0.81245876, 0.81105757],\n",
       "       [0.76532426, 0.77010456, 0.76823807, 0.76079677, 0.7625554 ],\n",
       "       [0.75650246, 0.75860852, 0.75834953, 0.75662481, 0.7542103 ],\n",
       "       [0.80371331, 0.7988016 , 0.80370621, 0.80052303, 0.79950099],\n",
       "       [0.78829595, 0.78920431, 0.78848906, 0.78926624, 0.78804843],\n",
       "       [0.73404101, 0.74157155, 0.73729682, 0.73029903, 0.73513638],\n",
       "       [0.72252252, 0.72649008, 0.72576451, 0.72538845, 0.71852081],\n",
       "       [0.77082506, 0.76955162, 0.76735617, 0.76565038, 0.76195427],\n",
       "       [0.74847335, 0.74765683, 0.74829975, 0.74869558, 0.74515222],\n",
       "       [0.70438008, 0.71555458, 0.7106086 , 0.7004532 , 0.70405932],\n",
       "       [0.68788935, 0.69587668, 0.69456647, 0.69504697, 0.68455973],\n",
       "       [0.75280999, 0.74518181, 0.74323049, 0.73982128, 0.74376229],\n",
       "       [0.71452268, 0.71481728, 0.71543005, 0.71649319, 0.70811914],\n",
       "       [0.67572714, 0.68725199, 0.68443874, 0.67228439, 0.67907241],\n",
       "       [0.65625368, 0.66345023, 0.66334621, 0.66376746, 0.65265896],\n",
       "       [0.72968495, 0.72706826, 0.7211285 , 0.71531894, 0.72403733],\n",
       "       [0.68308488, 0.68204879, 0.68342206, 0.68325399, 0.67507946],\n",
       "       [0.64790885, 0.66247313, 0.6622199 , 0.64956179, 0.65584184],\n",
       "       [0.62121146, 0.6290885 , 0.62970838, 0.62929169, 0.6201253 ],\n",
       "       [0.71199293, 0.70907995, 0.70080538, 0.69721927, 0.70284628],\n",
       "       [0.64690129, 0.64656881, 0.64962917, 0.6482717 , 0.63940674],\n",
       "       [0.62806205, 0.63998823, 0.63745103, 0.63030717, 0.63623009],\n",
       "       [0.58700849, 0.59618854, 0.59581934, 0.59671367, 0.58963979],\n",
       "       [0.70220952, 0.69077924, 0.67983355, 0.67961155, 0.69604166],\n",
       "       [0.60984981, 0.6091771 , 0.61303691, 0.61004746, 0.60154662],\n",
       "       [0.61079936, 0.62572278, 0.62872651, 0.61707437, 0.62437836],\n",
       "       [0.55565321, 0.56499275, 0.56470961, 0.5671245 , 0.56008039],\n",
       "       [0.68827961, 0.68136931, 0.67066615, 0.6735262 , 0.69071064],\n",
       "       [0.57391866, 0.57309689, 0.57766174, 0.57409011, 0.56547099],\n",
       "       [0.60691731, 0.61412462, 0.61519611, 0.60898461, 0.61670819],\n",
       "       [0.52286275, 0.53253954, 0.53227806, 0.53658458, 0.53017793],\n",
       "       [0.68214609, 0.67215755, 0.66585936, 0.67137328, 0.68591402],\n",
       "       [0.53965273, 0.53685333, 0.54156093, 0.53805408, 0.53033679],\n",
       "       [0.60136758, 0.60761556, 0.61122831, 0.60416626, 0.6127535 ],\n",
       "       [0.48818041, 0.49934537, 0.49824529, 0.50520712, 0.49673258],\n",
       "       [0.68766987, 0.67629929, 0.66160625, 0.67461523, 0.68391118],\n",
       "       [0.50504097, 0.49996675, 0.50579539, 0.50269821, 0.49609747],\n",
       "       [0.61189048, 0.60525502, 0.61360432, 0.60271979, 0.60887155],\n",
       "       [0.45329353, 0.46416759, 0.46367731, 0.47130625, 0.46542807],\n",
       "       [0.68895961, 0.67565821, 0.66912101, 0.68272745, 0.69283095],\n",
       "       [0.47107153, 0.46515384, 0.4711751 , 0.46767661, 0.46087632],\n",
       "       [0.61939067, 0.6093419 , 0.62145392, 0.60573169, 0.6107714 ],\n",
       "       [0.41714702, 0.42730034, 0.42799283, 0.43808502, 0.43229328],\n",
       "       [0.6970443 , 0.68141109, 0.67924616, 0.68678188, 0.69687405],\n",
       "       [0.43844124, 0.43189325, 0.43796745, 0.43434647, 0.42750078],\n",
       "       [0.61833636, 0.62060318, 0.62723269, 0.60813898, 0.61653046],\n",
       "       [0.38051576, 0.39209871, 0.39212719, 0.40453572, 0.39603993]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A more thorough check of different max depths, including comparison of performance on test and training.\n",
    "rmses = np.zeros((60, 5))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(df)):\n",
    "    ## get the kfold training data\n",
    "    X_train_train = df[features].iloc[train_index,:]\n",
    "    y_train_train = df['stay_length_minutes'].iloc[train_index]\n",
    "    \n",
    "    ## get the holdout data\n",
    "    X_holdout = df[features].iloc[test_index,:]\n",
    "    y_holdout = df['stay_length_minutes'].iloc[test_index]\n",
    "\n",
    "    ## Fit models\n",
    "    for k in range(15):\n",
    "        # Initialize models with dynamic max_depth values\n",
    "        model_tree_k = DecisionTreeRegressor(max_depth=k+5, random_state=108)\n",
    "        model_tree_nocc_k = DecisionTreeRegressor(max_depth=k+5, random_state=108)\n",
    "    \n",
    "        # Fit the models to the training data\n",
    "        model_tree_k.fit(X_train_train, y_train_train)\n",
    "        model_tree_nocc_k.fit(X_train_train[triage_physical_features+triage_other_features+demographic_features], y_train_train)\n",
    "\n",
    "        ## Use models to generate predictions on the holdout set\n",
    "        model_tree_preds_k = model_tree_k.predict(X_holdout)\n",
    "        model_tree_preds_train_k = model_tree_k.predict(X_train_train)\n",
    "\n",
    "        model_tree_nocc_preds_k = model_tree_nocc_k.predict(X_holdout[triage_physical_features+triage_other_features+demographic_features])\n",
    "        model_tree_nocc_preds_train_k = model_tree_nocc_k.predict(X_train_train[triage_physical_features+triage_other_features+demographic_features])\n",
    "\n",
    "        ## Record the rmses\n",
    "        rmses[4*k,i] = root_mean_squared_error(y_holdout, model_tree_preds_k)\n",
    "        rmses[4*k+1,i] = root_mean_squared_error(y_train_train, model_tree_preds_train_k)\n",
    "        rmses[4*k+2,i] = root_mean_squared_error(y_holdout, model_tree_nocc_preds_k)\n",
    "        rmses[4*k+3,i] = root_mean_squared_error(y_train_train, model_tree_nocc_preds_train_k)\n",
    "\n",
    "        print('Round', k, 'completed')\n",
    "        k=k+1\n",
    "\n",
    "rmses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_means=np.mean(rmses, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88078211, 0.87786269, 0.86788743, 0.86500973, 0.86317132,\n",
       "       0.85875208, 0.83719624, 0.8339429 , 0.84224358, 0.83643325,\n",
       "       0.80450281, 0.79964732, 0.82093382, 0.81192019, 0.76540381,\n",
       "       0.75685912, 0.80124903, 0.7886608 , 0.73566896, 0.72373727,\n",
       "       0.7670675 , 0.74765555, 0.70701116, 0.69158784, 0.74496117,\n",
       "       0.71387647, 0.67975494, 0.65989531, 0.7234476 , 0.68137784,\n",
       "       0.6556011 , 0.62588506, 0.70438876, 0.64615554, 0.63440772,\n",
       "       0.59307397, 0.6896951 , 0.60873158, 0.62134028, 0.56251209,\n",
       "       0.68091038, 0.57284768, 0.61238617, 0.53088858, 0.67549006,\n",
       "       0.53729157, 0.60742624, 0.49754215, 0.67682036, 0.50191976,\n",
       "       0.60846823, 0.46357455, 0.68185945, 0.46719068, 0.61333792,\n",
       "       0.4285637 , 0.6882715 , 0.43402984, 0.61816833, 0.39306346])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmses_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent drop in RMSE from test to training for depth 5 full model: -0.003314587403475457\n",
      "Percent drop in RMSE from test to training for depth 5 no CC model: -0.003315746257876459\n",
      "Percent drop in RMSE from test to training for depth 6 full model: -0.005119765098484738\n",
      "Percent drop in RMSE from test to training for depth 6 no CC model: -0.00388598710747646\n",
      "Percent drop in RMSE from test to training for depth 7 full model: -0.0068986340740119214\n",
      "Percent drop in RMSE from test to training for depth 7 no CC model: -0.006035394372794602\n",
      "Percent drop in RMSE from test to training for depth 8 full model: -0.010979724283583464\n",
      "Percent drop in RMSE from test to training for depth 8 no CC model: -0.011163632398782063\n",
      "Percent drop in RMSE from test to training for depth 9 full model: -0.015710759375987766\n",
      "Percent drop in RMSE from test to training for depth 9 no CC model: -0.01621882387846026\n",
      "Percent drop in RMSE from test to training for depth 10 full model: -0.025306704199588588\n",
      "Percent drop in RMSE from test to training for depth 10 no CC model: -0.021814815220483636\n",
      "Percent drop in RMSE from test to training for depth 11 full model: -0.04172661322235034\n",
      "Percent drop in RMSE from test to training for depth 11 no CC model: -0.029215864755972917\n",
      "Percent drop in RMSE from test to training for depth 12 full model: -0.0581517745077639\n",
      "Percent drop in RMSE from test to training for depth 12 no CC model: -0.045326400075161824\n",
      "Percent drop in RMSE from test to training for depth 13 full model: -0.08267199217965082\n",
      "Percent drop in RMSE from test to training for depth 13 no CC model: -0.06515329023517218\n",
      "Percent drop in RMSE from test to training for depth 14 full model: -0.11739031433062268\n",
      "Percent drop in RMSE from test to training for depth 14 no CC model: -0.09467949941125536\n",
      "Percent drop in RMSE from test to training for depth 15 full model: -0.1587032688630632\n",
      "Percent drop in RMSE from test to training for depth 15 no CC model: -0.13308202831636523\n",
      "Percent drop in RMSE from test to training for depth 16 full model: -0.20458996566780258\n",
      "Percent drop in RMSE from test to training for depth 16 no CC model: -0.18090112352680543\n",
      "Percent drop in RMSE from test to training for depth 17 full model: -0.2584151027608343\n",
      "Percent drop in RMSE from test to training for depth 17 no CC model: -0.2381285907778965\n",
      "Percent drop in RMSE from test to training for depth 18 full model: -0.314828468213722\n",
      "Percent drop in RMSE from test to training for depth 18 no CC model: -0.3012600663999005\n",
      "Percent drop in RMSE from test to training for depth 19 full model: -0.3693915229103934\n",
      "Percent drop in RMSE from test to training for depth 19 no CC model: -0.36414817488493406\n"
     ]
    }
   ],
   "source": [
    "#Looking at the percent change in RMSE going from test data to train data, from above cross validation, \n",
    "#for different math depths. Ideally we would get some minimum (I think) but here we just get that \n",
    "#the percent changes are increasing monotonically.\n",
    "\n",
    "for i in range(15):\n",
    "    diff_i=(rmses_means[4*i+1]-rmses_means[4*i])/rmses_means[4*i]\n",
    "    diff_nocc_i=(rmses_means[4*i+3]-rmses_means[4*i+2])/rmses_means[4*i+2]\n",
    "    print(\"Percent drop in RMSE from test to training for depth\", i+5,\"full model:\", diff_i)\n",
    "    print(\"Percent drop in RMSE from test to training for depth\", i+5,\"no CC model:\", diff_nocc_i)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edpredict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
