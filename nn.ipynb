{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:43.898920700Z",
     "start_time": "2025-03-30T23:16:42.849243100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from scipy.stats import permutation_test, f_oneway\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:46.959306700Z",
     "start_time": "2025-03-30T23:16:43.900919600Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../DataCleaning/train.csv')\n",
    "train = train.drop(columns = ['subject_id', 'hadm_id', 'stay_id', 'race', 'pain', 'intime', 'outtime'])\n",
    "\n",
    "train['race_condensed'] = train['race_condensed'].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:47.240264700Z",
     "start_time": "2025-03-30T23:16:46.953033900Z"
    }
   },
   "outputs": [],
   "source": [
    "train['tokenized_cp'] = train['chiefcomplaint'].str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:48.677903400Z",
     "start_time": "2025-03-30T23:16:47.241290100Z"
    }
   },
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=train[\"tokenized_cp\"], vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:48.693093700Z",
     "start_time": "2025-03-30T23:16:48.678907600Z"
    }
   },
   "outputs": [],
   "source": [
    "class Word2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.vector_size = model.vector_size\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # No fitting needed\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([self._get_sentence_embedding(words) for words in X])\n",
    "\n",
    "    def _get_sentence_embedding(self, words):\n",
    "        vectors = [self.model.wv[word] for word in words if word in self.model.wv]\n",
    "        return np.mean(vectors, axis=0) if vectors else np.zeros(self.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:48.711257900Z",
     "start_time": "2025-03-30T23:16:48.693093700Z"
    }
   },
   "outputs": [],
   "source": [
    "# text_pipeline = FeatureUnion([\n",
    "#     (\"tfidf\", TfidfVectorizer()),  # TF-IDF feature extraction\n",
    "#     (\"word2vec\", Word2VecTransformer(model=word2vec_model))  # Word2Vec feature extraction\n",
    "# ])\n",
    "# text_pipeline = FeatureUnion([  # TF-IDF feature extraction\n",
    "#     (\"word2vec\", Word2VecTransformer(model=word2vec_model))  # Word2Vec feature extraction\n",
    "# ])\n",
    "# text_pipeline = FeatureUnion([\n",
    "#     (\"tfidf\", TfidfVectorizer())  # Word2Vec feature extraction\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:48.723676700Z",
     "start_time": "2025-03-30T23:16:48.708241500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define feature lists\n",
    "cc_vars = [f\"cc_{i}\" for i in range(100)]  # These should be passed unchanged\n",
    "numeric_vars = ['admission_age', 'temperature', 'heartrate', 'resprate', 'o2sat', \n",
    "                'sbp', 'dbp', 'acuity', 'pain_cleaned_advanced']\n",
    "categorical_vars = ['gender', 'arrival_transport', 'race_condensed']\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=100, random_state=2025)),\n",
    "    ('scaler', StandardScaler())  # Standardize only selected numeric variables\n",
    "])\n",
    "\n",
    "cc_pipeline = FunctionTransformer(lambda x: x, validate=False)  # Pass through unchanged\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Define ColumnTransformer\n",
    "# impute_standardize = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numeric_pipeline, numeric_vars),  # Standardize selected numeric features\n",
    "#         ('cc', cc_pipeline, cc_vars),  # Pass `cc_*` variables unchanged\n",
    "#         ('cat', categorical_pipeline, categorical_vars),\n",
    "#         (\"text\", TfidfVectorizer(), \"chiefcomplaint\"),\n",
    "#         (\"word2vec\", Word2VecTransformer(model=word2vec_model), \"chiefcomplaint\")\n",
    "#     ]\n",
    "# )\n",
    "impute_standardize = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_vars),\n",
    "        ('cat', categorical_pipeline, categorical_vars),\n",
    "        (\"text\", TfidfVectorizer(), \"chiefcomplaint\"),\n",
    "        (\"word2vec\", Word2VecTransformer(model=word2vec_model), \"chiefcomplaint\")\n",
    "    ]\n",
    ")\n",
    "model = Pipeline(steps=[(\"pre\", impute_standardize), (\"model\", XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42))])\n",
    "# model = Pipeline(steps=[(\"pre\", impute_standardize), (\"model\", LinearRegression())])\n",
    "# model = Pipeline(steps=[(\"pre\", impute_standardize), (\"model\", Ridge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:48.741276500Z",
     "start_time": "2025-03-30T23:16:48.725693200Z"
    }
   },
   "outputs": [],
   "source": [
    "train['race_condensed'] = train['race_condensed'].fillna('Missing')\n",
    "\n",
    "# numeric_vars = ['admission_age', 'temperature', 'heartrate', 'resprate', 'o2sat', \n",
    "#                 'sbp', 'dbp', 'acuity', 'stay_length_minutes', 'pain_cleaned_advanced']\n",
    "numeric_vars = ['admission_age', 'temperature', 'heartrate', 'resprate', 'o2sat', \n",
    "                'sbp', 'dbp', 'acuity', 'pain_cleaned_advanced'] + [f\"cc_{i}\" for i in range(100)]\n",
    "categorical_vars = ['gender', 'arrival_transport', 'race_condensed']\n",
    "\n",
    "numeric = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=100, random_state=2025)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "impute_standardize = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric, numeric_vars),\n",
    "        ('cat', categorical, categorical_vars),\n",
    "        (\"text\", TfidfVectorizer(), \"chiefcomplaint\"),\n",
    "        (\"word2vec\", Word2VecTransformer(model=word2vec_model), \"chiefcomplaint\")\n",
    "\n",
    "    ])\n",
    "impute_standardize = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric, numeric_vars),\n",
    "        ('cat', categorical, categorical_vars)\n",
    "\n",
    "    ])\n",
    "# model = Pipeline(steps=[(\"pre\", impute_standardize), (\"text\", FeatureUnion([\n",
    "#             (\"tfidf\", TfidfVectorizer()),  # TF-IDF vectorization\n",
    "#             (\"word2vec\", Word2VecTransformer(model=word2vec_model))  # Word2Vec embeddings\n",
    "#         ]), \"chiefcomplaint\")])\n",
    "# # model = Pipeline(steps=[(\"pre\", impute_standardize), (\"model\", XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42))])\n",
    "# model = Pipeline(steps=[(\"pre\", impute_standardize), (\"model\", LinearRegression())])\n",
    "# # model = Pipeline(steps=[(\"pre\", impute_standardize), (\"model\", Ridge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:48.799923700Z",
     "start_time": "2025-03-30T23:16:48.739212600Z"
    }
   },
   "outputs": [],
   "source": [
    "# X = train.drop(columns=(['stay_length_minutes', 'tokenized_cp'] + [f\"cc_{i}\" for i in range(100)]))\n",
    "X = train.drop(columns=(['stay_length_minutes', 'tokenized_cp', 'chiefcomplaint']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:48.815216300Z",
     "start_time": "2025-03-30T23:16:48.800944400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:50.770923800Z",
     "start_time": "2025-03-30T23:16:48.817344800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zym97\\AppData\\Local\\Temp\\ipykernel_6740\\1985296285.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].mean(), inplace=True)\n",
      "C:\\Users\\zym97\\AppData\\Local\\Temp\\ipykernel_6740\\1985296285.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "for col in X.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    X[col].fillna(X[col].mean(), inplace=True)\n",
    "\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    X[col].fillna(X[col].mode()[0], inplace=True)\n",
    "\n",
    "df_encoded = pd.get_dummies(X, columns=['gender', 'arrival_transport', 'race_condensed'])\n",
    "# \n",
    "X_tensor = torch.tensor(df_encoded.astype(float).values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:50.786577Z",
     "start_time": "2025-03-30T23:16:50.771933100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([368975, 124])\n"
     ]
    }
   ],
   "source": [
    "print(X_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:50.830539200Z",
     "start_time": "2025-03-30T23:16:50.787580700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([368975])\n"
     ]
    }
   ],
   "source": [
    "y = train['stay_length_minutes']\n",
    "y=y.to_numpy()\n",
    "y_tensor = torch.from_numpy(y)\n",
    "print(y_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:51.168472Z",
     "start_time": "2025-03-30T23:16:50.803749900Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../DataCleaning/test.csv')\n",
    "test = test.drop(columns = ['subject_id', 'hadm_id', 'stay_id', 'race', 'pain', 'intime', 'outtime'])\n",
    "\n",
    "test['race_condensed'] = test['race_condensed'].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:51.184523600Z",
     "start_time": "2025-03-30T23:16:51.168472Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_test = test.drop(columns=(['stay_length_minutes'] + [f\"cc_{i}\" for i in range(100)]))\n",
    "X_test = test.drop(columns=(['stay_length_minutes', 'chiefcomplaint']))\n",
    "y_test  = test['stay_length_minutes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:51.261109Z",
     "start_time": "2025-03-30T23:16:51.185538100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zym97\\AppData\\Local\\Temp\\ipykernel_6740\\3735147754.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(X_test[col].mean(), inplace=True)\n",
      "C:\\Users\\zym97\\AppData\\Local\\Temp\\ipykernel_6740\\3735147754.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(X_test[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "for col in X_test.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    X_test[col].fillna(X_test[col].mean(), inplace=True)\n",
    "\n",
    "for col in X_test.select_dtypes(include='object').columns:\n",
    "    X_test[col].fillna(X_test[col].mode()[0], inplace=True)\n",
    "\n",
    "df_encoded = pd.get_dummies(X_test, columns=['gender', 'arrival_transport', 'race_condensed'])\n",
    "# \n",
    "X_test_tensor = torch.tensor(df_encoded.astype(float).values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:51.276304Z",
     "start_time": "2025-03-30T23:16:51.262109100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40998, 124])\n"
     ]
    }
   ],
   "source": [
    "print(X_test_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:51.320398200Z",
     "start_time": "2025-03-30T23:16:51.277309200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40998])\n"
     ]
    }
   ],
   "source": [
    "y_test=y_test.to_numpy()\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "print(y_test_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:16:51.320398200Z",
     "start_time": "2025-03-30T23:16:51.293698700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        prev_dim = input_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        layers.append(nn.Linear(prev_dim, 1))  # Final regression output\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:47:44.377824400Z",
     "start_time": "2025-03-30T23:16:51.309265900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train RMSE: 375.7097 | Test RMSE: 378.8504\n",
      "Epoch 2/100 | Train RMSE: 366.1204 | Test RMSE: 370.6698\n",
      "Epoch 3/100 | Train RMSE: 364.5161 | Test RMSE: 377.2680\n",
      "Epoch 4/100 | Train RMSE: 363.3368 | Test RMSE: 369.1485\n",
      "Epoch 5/100 | Train RMSE: 362.4412 | Test RMSE: 369.0166\n",
      "Epoch 6/100 | Train RMSE: 361.9067 | Test RMSE: 367.9326\n",
      "Epoch 7/100 | Train RMSE: 361.0014 | Test RMSE: 368.1744\n",
      "Epoch 8/100 | Train RMSE: 361.2767 | Test RMSE: 367.1302\n",
      "Epoch 9/100 | Train RMSE: 360.6335 | Test RMSE: 369.0350\n",
      "Epoch 10/100 | Train RMSE: 359.9389 | Test RMSE: 367.9157\n",
      "Epoch 11/100 | Train RMSE: 360.2449 | Test RMSE: 368.7642\n",
      "Epoch 12/100 | Train RMSE: 359.9060 | Test RMSE: 367.3842\n",
      "Epoch 13/100 | Train RMSE: 359.8822 | Test RMSE: 367.7858\n",
      "Epoch 14/100 | Train RMSE: 359.3370 | Test RMSE: 367.0089\n",
      "Epoch 15/100 | Train RMSE: 359.2438 | Test RMSE: 366.0707\n",
      "Epoch 16/100 | Train RMSE: 359.3835 | Test RMSE: 368.3567\n",
      "Epoch 17/100 | Train RMSE: 358.8305 | Test RMSE: 367.0146\n",
      "Epoch 18/100 | Train RMSE: 358.4730 | Test RMSE: 366.7135\n",
      "Epoch 19/100 | Train RMSE: 358.8142 | Test RMSE: 366.0675\n",
      "Epoch 20/100 | Train RMSE: 358.8187 | Test RMSE: 366.0350\n",
      "Epoch 21/100 | Train RMSE: 358.7788 | Test RMSE: 366.2209\n",
      "Epoch 22/100 | Train RMSE: 358.6973 | Test RMSE: 368.2039\n",
      "Epoch 23/100 | Train RMSE: 358.2841 | Test RMSE: 366.0319\n",
      "Epoch 24/100 | Train RMSE: 358.3282 | Test RMSE: 365.7370\n",
      "Epoch 25/100 | Train RMSE: 358.4310 | Test RMSE: 365.2741\n",
      "Epoch 26/100 | Train RMSE: 358.2678 | Test RMSE: 365.7421\n",
      "Epoch 27/100 | Train RMSE: 358.2399 | Test RMSE: 367.4226\n",
      "Epoch 28/100 | Train RMSE: 358.0394 | Test RMSE: 365.7822\n",
      "Epoch 29/100 | Train RMSE: 358.0089 | Test RMSE: 367.0341\n",
      "Epoch 30/100 | Train RMSE: 357.8961 | Test RMSE: 365.6282\n",
      "Epoch 31/100 | Train RMSE: 357.7296 | Test RMSE: 367.2703\n",
      "Epoch 32/100 | Train RMSE: 357.2871 | Test RMSE: 365.3652\n",
      "Epoch 33/100 | Train RMSE: 357.7927 | Test RMSE: 366.5565\n",
      "Epoch 34/100 | Train RMSE: 357.3248 | Test RMSE: 366.3650\n",
      "Epoch 35/100 | Train RMSE: 357.3934 | Test RMSE: 367.5417\n",
      "Epoch 36/100 | Train RMSE: 357.2975 | Test RMSE: 366.0608\n",
      "Epoch 37/100 | Train RMSE: 357.1168 | Test RMSE: 365.0688\n",
      "Epoch 38/100 | Train RMSE: 357.2218 | Test RMSE: 365.0935\n",
      "Epoch 39/100 | Train RMSE: 357.2396 | Test RMSE: 365.8553\n",
      "Epoch 40/100 | Train RMSE: 356.5788 | Test RMSE: 365.8038\n",
      "Epoch 41/100 | Train RMSE: 356.9646 | Test RMSE: 365.0964\n",
      "Epoch 42/100 | Train RMSE: 356.9347 | Test RMSE: 365.0684\n",
      "Epoch 43/100 | Train RMSE: 356.3890 | Test RMSE: 364.9604\n",
      "Epoch 44/100 | Train RMSE: 356.8742 | Test RMSE: 367.2908\n",
      "Epoch 45/100 | Train RMSE: 356.7030 | Test RMSE: 366.1697\n",
      "Epoch 46/100 | Train RMSE: 356.7072 | Test RMSE: 365.9125\n",
      "Epoch 47/100 | Train RMSE: 356.5476 | Test RMSE: 364.9685\n",
      "Epoch 48/100 | Train RMSE: 356.3565 | Test RMSE: 367.2360\n",
      "Epoch 49/100 | Train RMSE: 356.3203 | Test RMSE: 365.7418\n",
      "Epoch 50/100 | Train RMSE: 356.4752 | Test RMSE: 370.7385\n",
      "Epoch 51/100 | Train RMSE: 356.3218 | Test RMSE: 364.7939\n",
      "Epoch 52/100 | Train RMSE: 356.1555 | Test RMSE: 365.5667\n",
      "Epoch 53/100 | Train RMSE: 356.2863 | Test RMSE: 366.3880\n",
      "Epoch 54/100 | Train RMSE: 356.0270 | Test RMSE: 365.4999\n",
      "Epoch 55/100 | Train RMSE: 356.0923 | Test RMSE: 365.1081\n",
      "Epoch 56/100 | Train RMSE: 355.9128 | Test RMSE: 366.9691\n",
      "Epoch 57/100 | Train RMSE: 355.8004 | Test RMSE: 366.0055\n",
      "Epoch 58/100 | Train RMSE: 355.8142 | Test RMSE: 366.8914\n",
      "Epoch 59/100 | Train RMSE: 355.5051 | Test RMSE: 365.0047\n",
      "Epoch 60/100 | Train RMSE: 355.7467 | Test RMSE: 365.1628\n",
      "Epoch 61/100 | Train RMSE: 355.6304 | Test RMSE: 366.2179\n",
      "Epoch 62/100 | Train RMSE: 355.3989 | Test RMSE: 364.9592\n",
      "Epoch 63/100 | Train RMSE: 355.5590 | Test RMSE: 365.5863\n",
      "Epoch 64/100 | Train RMSE: 355.5853 | Test RMSE: 365.5211\n",
      "Epoch 65/100 | Train RMSE: 355.2724 | Test RMSE: 366.1981\n",
      "Epoch 66/100 | Train RMSE: 355.1186 | Test RMSE: 365.2397\n",
      "Epoch 67/100 | Train RMSE: 355.4664 | Test RMSE: 365.5611\n",
      "Epoch 68/100 | Train RMSE: 355.1079 | Test RMSE: 365.6306\n",
      "Epoch 69/100 | Train RMSE: 354.9825 | Test RMSE: 365.6714\n",
      "Epoch 70/100 | Train RMSE: 355.0802 | Test RMSE: 365.7389\n",
      "Epoch 71/100 | Train RMSE: 354.7174 | Test RMSE: 366.7037\n",
      "Epoch 72/100 | Train RMSE: 354.8798 | Test RMSE: 365.3553\n",
      "Epoch 73/100 | Train RMSE: 354.7210 | Test RMSE: 365.4050\n",
      "Epoch 74/100 | Train RMSE: 354.7228 | Test RMSE: 366.0700\n",
      "Epoch 75/100 | Train RMSE: 354.5391 | Test RMSE: 365.6558\n",
      "Epoch 76/100 | Train RMSE: 354.3429 | Test RMSE: 367.6831\n",
      "Epoch 77/100 | Train RMSE: 354.6184 | Test RMSE: 366.9643\n",
      "Epoch 78/100 | Train RMSE: 354.4235 | Test RMSE: 365.5212\n",
      "Epoch 79/100 | Train RMSE: 354.2650 | Test RMSE: 366.2527\n",
      "Epoch 80/100 | Train RMSE: 353.9672 | Test RMSE: 365.9960\n",
      "Epoch 81/100 | Train RMSE: 354.3848 | Test RMSE: 366.5353\n",
      "Epoch 82/100 | Train RMSE: 354.4156 | Test RMSE: 366.3848\n",
      "Epoch 83/100 | Train RMSE: 354.0878 | Test RMSE: 365.8298\n",
      "Epoch 84/100 | Train RMSE: 353.7707 | Test RMSE: 366.2087\n",
      "Epoch 85/100 | Train RMSE: 354.0015 | Test RMSE: 365.9263\n",
      "Epoch 86/100 | Train RMSE: 354.0067 | Test RMSE: 365.7997\n",
      "Epoch 87/100 | Train RMSE: 353.7070 | Test RMSE: 367.4616\n",
      "Epoch 88/100 | Train RMSE: 353.9076 | Test RMSE: 367.7427\n",
      "Epoch 89/100 | Train RMSE: 353.8398 | Test RMSE: 367.8549\n",
      "Epoch 90/100 | Train RMSE: 353.6278 | Test RMSE: 369.1349\n",
      "Epoch 91/100 | Train RMSE: 353.4469 | Test RMSE: 367.7736\n",
      "Epoch 92/100 | Train RMSE: 353.3220 | Test RMSE: 366.6621\n",
      "Epoch 93/100 | Train RMSE: 353.1979 | Test RMSE: 367.4924\n",
      "Epoch 94/100 | Train RMSE: 353.2328 | Test RMSE: 366.2211\n",
      "Epoch 95/100 | Train RMSE: 353.3525 | Test RMSE: 365.9740\n",
      "Epoch 96/100 | Train RMSE: 352.5886 | Test RMSE: 366.3793\n",
      "Epoch 97/100 | Train RMSE: 353.1260 | Test RMSE: 368.1646\n",
      "Epoch 98/100 | Train RMSE: 352.9283 | Test RMSE: 368.8099\n",
      "Epoch 99/100 | Train RMSE: 353.3147 | Test RMSE: 366.8840\n",
      "Epoch 100/100 | Train RMSE: 352.7328 | Test RMSE: 366.7480\n"
     ]
    }
   ],
   "source": [
    "def rmse_loss(pred, target):\n",
    "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
    "\n",
    "# Make sure y is of shape [n, 1]\n",
    "if y_tensor.ndim == 1:\n",
    "    y_tensor = y_tensor.unsqueeze(1)\n",
    "if y_test_tensor.ndim == 1:\n",
    "    y_test_tensor = y_test_tensor.unsqueeze(1)\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "batch_size = 512\n",
    "train_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "input_dim = X_tensor.shape[1]\n",
    "hidden_dims = [512, 512, 512, 512, 512, 512]\n",
    "model = MLP(input_dim=X_tensor.shape[1], hidden_dims=hidden_dims)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch_X)\n",
    "        loss = rmse_loss(pred, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_preds = model(X_test_tensor)\n",
    "        test_loss = rmse_loss(test_preds, y_test_tensor).item()\n",
    "\n",
    "    if (epoch + 1) % 1 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train RMSE: {avg_train_loss:.4f} | Test RMSE: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T23:47:44.392978200Z",
     "start_time": "2025-03-30T23:47:44.375812600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
